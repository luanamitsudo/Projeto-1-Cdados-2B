{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Andressa Silva de Oliveira\n",
    "\n",
    "Nome: Luana Mitsudo Coelho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aten√ß√£o:** Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import functools\n",
    "import operator\n",
    "import re\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Em `filename`, coloque o nome do seu arquivo de dados!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo xiaomi.xlsx, tudo certo para prosseguir com a prova!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filename = 'xiaomi.xlsx'\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com a prova!')\n",
    "else:\n",
    "    print(f'N√£o encontrei o arquivo {filename} aqui no diret√≥rio {os.getcwd()}, ser√° que voc√™ n√£o baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Valor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@miuirom miui 12 no rn8 xiaomi cade?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt @dani13_f: meu cell note 8 xiaomi j√° t√° com...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@notfakeholmes @brenomarquesof @arcanjobeni 3 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@juliaaacras o da xiaomi √© excelente, sem mais</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@rrlleal00 xiaomi mi 9 se. comprei na amazon e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Valor\n",
       "0               @miuirom miui 12 no rn8 xiaomi cade?      1\n",
       "1  rt @dani13_f: meu cell note 8 xiaomi j√° t√° com...      1\n",
       "2  @notfakeholmes @brenomarquesof @arcanjobeni 3 ...      1\n",
       "3     @juliaaacras o da xiaomi √© excelente, sem mais      1\n",
       "4  @rrlleal00 xiaomi mi 9 se. comprei na amazon e...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Valor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vcs acham msm que a c√¢mera d xiaomi √© melhor q...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pq as autorizadas do xiaomi s√≥ s√£o no toba do ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>üî• em stock! smart tvs xiaomi ao pre√ßo que quer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xiaomi poco x3 √© um verdadeiro sucesso de vend...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>quero refazer pq na √©poca eu usava o iphone 7 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Valor\n",
       "0  vcs acham msm que a c√¢mera d xiaomi √© melhor q...      1\n",
       "1  pq as autorizadas do xiaomi s√≥ s√£o no toba do ...      1\n",
       "2  üî• em stock! smart tvs xiaomi ao pre√ßo que quer...      0\n",
       "3  xiaomi poco x3 √© um verdadeiro sucesso de vend...      1\n",
       "4  quero refazer pq na √©poca eu usava o iphone 7 ...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "Escolhemos a marca Xiaomi e consideramos, para fins de an√°lise, que os tweets relevantes s√£o aqueles que elogiam de alguma forma, pedem melhorias ou criticam a marca e seus produtos. Na categoria n√£o relevantes foram classificados os tweets de propagandas de lojas e aqueles que mencionam o nome da marca mas n√£o se encaixam nas categorias j√° mencionadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√≥digo para limpeza dos dados\n",
    "# https://docs.python.org/3/library/re.html#\n",
    "import re \n",
    "def cleanup(text):\n",
    "    punctuation = '[!-.:?;]' \n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpando a base de dados para Treinamento\n",
    "treinamento_limpo = cleanup(\" \".join(train.Treinamento).lower())\n",
    "em = treinamento_limpo\n",
    "em_split_emoji = emoji.get_emoji_regexp().split(em)\n",
    "em_split_whitespace = [substr.split() for substr in em_split_emoji]\n",
    "palavras_train = functools.reduce(operator.concat, em_split_whitespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    @miuirom\n",
       "1                        miui\n",
       "2                          12\n",
       "3                          no\n",
       "4                         rn8\n",
       "                ...          \n",
       "7263                      g5s\n",
       "7264                   xiaomi\n",
       "7265                       mi\n",
       "7266                       a2\n",
       "7267    https//tco/gtqmqfuxso\n",
       "Length: 7268, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertendo treinamento em pd.Series\n",
    "serie_train = pd.Series(palavras_train)\n",
    "serie_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xiaomi    361\n",
       "o         190\n",
       "e         156\n",
       "de        156\n",
       "que       155\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tabela absoluta de treinamento\n",
    "tabela_train_absoluta = serie_train.value_counts()\n",
    "tabela_train_absoluta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xiaomi    0.049670\n",
       "o         0.026142\n",
       "e         0.021464\n",
       "de        0.021464\n",
       "que       0.021326\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tabela relativa de treinamento\n",
    "tabela_train_relativa = serie_train.value_counts(True)\n",
    "tabela_train_relativa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa√ß√£o de tweets em relevantes e irrelevantes\n",
    "dados_R = train.loc[train.Valor == 1,:]\n",
    "dados_I = train.loc[train.Valor == 0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizando a base de dados separada em relevantes e irrelevantes\n",
    "dados_R_limpo = cleanup(\" \".join(dados_R.Treinamento).lower())\n",
    "dados_I_limpo = cleanup(\" \".join(dados_I.Treinamento).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa√ß√£o de palavras pertencentes a twittes relevantes e irrelevantes\n",
    "palavras_dados_R = dados_R_limpo.split()\n",
    "palavras_dados_I = dados_I_limpo.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41456582633053224\n",
      "0.5854341736694678\n"
     ]
    }
   ],
   "source": [
    "# Probabilidade de um tweet ser relevante ou irrelevante\n",
    "prob_relev = train.Valor.value_counts(True, sort=False)\n",
    "P_R = prob_relev[1]\n",
    "P_I = prob_relev[0]\n",
    "print(P_R)\n",
    "print(P_I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xiaomi    152\n",
       "o         103\n",
       "redmi      84\n",
       "e          84\n",
       "a          84\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tabela de frequ√™ncias para palavras relevantes\n",
    "tabela_R = pd.Series(palavras_dados_R).value_counts()\n",
    "tabela_R.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xiaomi    209\n",
       "o          87\n",
       "que        76\n",
       "de         74\n",
       "e          72\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tabela de frequ√™ncias para palavras irrelevantes\n",
    "tabela_I = pd.Series(palavras_dados_I).value_counts()\n",
    "tabela_I.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3572"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total de palavras relevantes\n",
    "total_R = tabela_R.sum()\n",
    "total_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3604"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total de palavras irrelevantes\n",
    "total_I = tabela_I.sum()\n",
    "total_I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpando a base de dados para teste e armazenando em uma nova coluna\n",
    "cont = 0\n",
    "for a in test.Teste:\n",
    "    teste_limpo = cleanup(a).lower()\n",
    "    test.loc[cont,'Limpos'] = teste_limpo\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Valor</th>\n",
       "      <th>Limpos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vcs acham msm que a c√¢mera d xiaomi √© melhor q...</td>\n",
       "      <td>1</td>\n",
       "      <td>vcs acham msm que a c√¢mera d xiaomi √© melhor q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pq as autorizadas do xiaomi s√≥ s√£o no toba do ...</td>\n",
       "      <td>1</td>\n",
       "      <td>pq as autorizadas do xiaomi s√≥ s√£o no toba do ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>üî• em stock! smart tvs xiaomi ao pre√ßo que quer...</td>\n",
       "      <td>0</td>\n",
       "      <td>üî• em stock smart tvs xiaomi ao pre√ßo que queri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xiaomi poco x3 √© um verdadeiro sucesso de vend...</td>\n",
       "      <td>1</td>\n",
       "      <td>xiaomi poco x3 √© um verdadeiro sucesso de vend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>quero refazer pq na √©poca eu usava o iphone 7 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>quero refazer pq na √©poca eu usava o iphone 7 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Valor  \\\n",
       "0  vcs acham msm que a c√¢mera d xiaomi √© melhor q...      1   \n",
       "1  pq as autorizadas do xiaomi s√≥ s√£o no toba do ...      1   \n",
       "2  üî• em stock! smart tvs xiaomi ao pre√ßo que quer...      0   \n",
       "3  xiaomi poco x3 √© um verdadeiro sucesso de vend...      1   \n",
       "4  quero refazer pq na √©poca eu usava o iphone 7 ...      1   \n",
       "\n",
       "                                              Limpos  \n",
       "0  vcs acham msm que a c√¢mera d xiaomi √© melhor q...  \n",
       "1  pq as autorizadas do xiaomi s√≥ s√£o no toba do ...  \n",
       "2  üî• em stock smart tvs xiaomi ao pre√ßo que queri...  \n",
       "3  xiaomi poco x3 √© um verdadeiro sucesso de vend...  \n",
       "4  quero refazer pq na √©poca eu usava o iphone 7 ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando a coluna nova\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando o tipo de dados da coluna teste\n",
    "type(test.Teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando os tweets em listas de palavras\n",
    "lista_palavras_separadas = []\n",
    "for frase in test.Limpos:\n",
    "    em = frase\n",
    "    em_split_emoji = emoji.get_emoji_regexp().split(em)\n",
    "    em_split_whitespace = [substr.split() for substr in em_split_emoji]\n",
    "    palavras_test = functools.reduce(operator.concat, em_split_whitespace)\n",
    "    lista_palavras_separadas.append(palavras_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando as probabilidades de relev√¢ncia em um tweet a partir do classificador desenvolvido\n",
    "i = 0\n",
    "a = 0\n",
    "while i < len(lista_palavras_separadas):\n",
    "    Prob_frase_R = 1\n",
    "    Prob_frase_I = 1\n",
    "    \n",
    "    for a in (lista_palavras_separadas[i]):\n",
    "        if a not in tabela_R:\n",
    "            Prob_frase_R *= ((0+1)/(total_R + (total_R+total_I)))\n",
    "\n",
    "        else:\n",
    "            Prob_frase_R *= (tabela_R[a] + 1)/(total_R + (total_R+total_I))\n",
    "            \n",
    "        if a not in tabela_I:\n",
    "            Prob_frase_I *= ((0+1)/(total_R + (total_R+total_I)))\n",
    "\n",
    "        else:\n",
    "            Prob_frase_I *= ((tabela_I[a] +1)/(total_R + (total_R+total_I)))\n",
    "            \n",
    "    if (Prob_frase_R*P_R) > (Prob_frase_I*P_I):\n",
    "        test.loc[i,'Classificador'] = 1\n",
    "    else:\n",
    "        test.loc[i,'Classificador'] = 0\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Valor</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classificador</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>82</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>37</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Valor           0   1\n",
       "Classificador        \n",
       "0.0            82  25\n",
       "1.0            37  55"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tabela comparativa da classifica√ß√£o do modelo com a nossa\n",
    "tab = pd.crosstab(test['Classificador'],test['Valor'])\n",
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de verdadeiros positivos = 0.5978260869565217\n",
      "Porcentagem de falsos positivos = 0.40217391304347827\n",
      "Porcentagem de verdadeiros negativos = 0.7663551401869159\n",
      "Porcentagem de falsos negativos = 0.2336448598130841\n"
     ]
    }
   ],
   "source": [
    "# Par√¢metros obtidos a partir da tabela - Porcentagens calculadas em rela√ß√£o ao total de tweets dados pelo classificador como relevantes ou irrelevantes \n",
    "\n",
    "Porc_R_classif_R = (tab[1][1]/(tab[0][1]+tab[1][1]))\n",
    "Porc_I_classif_R = (tab[0][1]/(tab[0][1]+tab[1][1]))\n",
    "Porc_I_classif_I = (tab[0][0]/(tab[0][0]+tab[1][0]))\n",
    "Porc_R_classif_I = (tab[1][0]/(tab[1][0]+tab[0][0]))\n",
    "\n",
    "print(f'Porcentagem de verdadeiros positivos = {Porc_R_classif_R}')\n",
    "print(f'Porcentagem de falsos positivos = {Porc_I_classif_R}')\n",
    "print(f'Porcentagem de verdadeiros negativos = {Porc_I_classif_I}')  \n",
    "print(f'Porcentagem de falsos negativos = {Porc_R_classif_I}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diferen√ßa entre verdadeiros positivos e falsos positivos, em porcentagem = 19.565217391304344\n",
      "Diferen√ßa entre verdadeiros negativos e falsos negativos, em porcentagem = 53.271028037383175\n"
     ]
    }
   ],
   "source": [
    "# Par√¢metros comparativos sobre a performance do classificador\n",
    "relacao_vp_fp = (Porc_R_classif_R - Porc_I_classif_R)*100\n",
    "relacao_vn_fn = (Porc_I_classif_I - Porc_R_classif_I)*100\n",
    "\n",
    "print(f'Diferen√ßa entre verdadeiros positivos e falsos positivos, em porcentagem = {relacao_vp_fp}')\n",
    "print(f'Diferen√ßa entre verdadeiros negativos e falsos negativos, em porcentagem = {relacao_vn_fn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Comparativo qualitativo sobre os percentuais obtidos para discuss√£o da performance do classificador.\n",
    "\n",
    "    Com base nas porcentagens obtidas acima, percebe-se que o classificador, ainda em seu primeiro MVP, \n",
    "    apresenta uma performance satisfat√≥ria, fornecendo analises de qualidade sobre os dados coletados, \n",
    "    uma vez que os valores obtidos para porcentagens de verdadeiros positivos e verdadeiros negativos \n",
    "    superam as porcentagens de falsos positivos e falsos negativos em, respectivamente, 19,56% e 53,27%.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Explique como s√£o tratadas as mensagens com dupla nega√ß√£o e sarcasmo.\n",
    "\n",
    "   Para a an√°lise de mensagens com dupla nega√ß√£o, tomou-se, como exemplo, a seguinte frase da base de teste: \"vcs acham msm \n",
    "que a c√¢mera d xiaomi √© melhor que iphone que coragy n√£o chega nem fodendo pode ter quantos mp quiser fii\". Nesse caso, percebeu-se que a frase foi rotulada, pelo classificador, como relevante, recebendo valor 1, o mesmo atribu√≠do manualmente na etapa inicial do projeto.\n",
    "    J√° para a an√°lise de mensagens com sarcasmo, toma-se como exemplo o seguinte tweet: \"atualiza√ß√£o sobre meus xiaomi airdots bateria agora dura 10 minutos\". Nesse caso, o classificador atribuiu o valor 1, tendo considerado esse tweet como relevante, enquanto o valor atribu√≠do manualmente na etapa inicial foi o de irrelevante.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Proposta de plano de expans√£o. Por que nosso projeto deve continuar sendo financiado? \n",
    "\n",
    "    O classificador Naive-Bayes √© uma ferramenta que tem sido amplamente utilizada para a an√°lise de textos, \n",
    "    apresentando n√≠veis de qualidade que se destacam com rela√ß√£o a outras ferramentas que possuem o mesmo \n",
    "    prop√≥sito. Nesse contexto,considerando-se a an√°lise dos dados obtidos acerca do funcionamento do \n",
    "    classificador constru√≠do longo deste arquivo, pode-se perceber que, mesmo em sua primeira vers√£o, \n",
    "    ele apresentou resultados satisfat√≥rios, com uma assertividade maior do que 55% na avalia√ß√£o dos tweets \n",
    "    como relevantes ou irrelevantes. Al√©m disso, mediante a realiza√ß√£o dos aprimoramentos pretendidos: aumentar \n",
    "    a base de dados  considerada para a constru√ß√£o do classificador, criar categorias intermedi√°rias de relev√¢ncia \n",
    "    considerando a probabilidade, considerar as rela√ß√µes discursivas entre pares de palavras e, inclusive, buscar \n",
    "    diminuir a suposi√ß√£o de independ√™ncia entre as palavras por meio de procedimentos como o uso de m√©todos de \n",
    "    regress√£o, que  v√™m sendo estudados, a performance tornaria-se ainda mais precisa e coerente, aumentando a \n",
    "    assertividade das an√°lises fornecidas. Dessa forma, a continuidade do financiamento do projeto, traria grandes \n",
    "    lucros para a empresa de interesse em termos de compreens√£o das necessidades do usu√°rio e de percep√ß√£o de \n",
    "    poss√≠veis melhorias para alavancar os seus produtos e a sua imagem no mercado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Por que n√£o se deve alimentar a base de Treinamento automaticamente usando o pr√≥prio classificador, aplicado a novos tweets.\n",
    "\n",
    "    A base de treinamento n√£o pode ser alimentada automaticamente com o uso do pr√≥prio classificador \n",
    "    uma vez que este aprende com os tweets j√° classificados manualmente como relevantes ou irrelevantes. \n",
    "    Dessa forma, se o classificador criasse novos tweets para sua base de treinamento, ele n√£o estaria \n",
    "    aperfei√ßoando a sua an√°lise, mas sim aplicando aquilo que j√° aprendeu anteriomente, ent√£o n√£o haveria \n",
    "    melhora na precis√£o das previs√µes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Propostas de diferentes cen√°rios de uso para o classificador Naive-Bayes.\n",
    "\n",
    "    Dentre os cen√°rios em que se pode usar o classificador Naive-Bayes, t√™m-se:\n",
    "    - Filtrar an√∫ncios em sites de forma personalizada para cada usu√°rio, classificando como relevantes aqueles que \n",
    "    anunciam produtos, sites e servi√ßos que a pessoa usualmente busca;\n",
    "    - Filtrar e-mails, classificando-os como spam, principais, etc. de acordo com o conte√∫do (Por exemplo: se √© \n",
    "    propaganda ou n√£o), com o remetente (Por exemplo: se √© um contato frequente ou uma conta comercial), dentre \n",
    "    outras vari√°veis;\n",
    "    - Configurar um site a partir da atribui√ß√£o de t√≥picos (Topic Tagging) aos textos nele presentes. Dessa forma, \n",
    "    um texto pode, automaticamente, receber algumas classifica√ß√µes (Por exemplo: Um site pode ter suas mat√©rias \n",
    "    categorizadas como pertencentes aos t√≥picos \"esporte\", \"cultura\", \"moda\", dentre outros);\n",
    "    - Detectar fraudes em transa√ß√µes financeiras, identificando se  s√£o \"legais\" ou \"suspeitas\";\n",
    "    - Classificar clientes como \"alto\", \"m√©dio\" ou \"baixo\" risco para aprova√ß√£o de cr√©dito;\n",
    "    - Na √°rea de bioinform√°tica, identificar a classe de prote√≠nas e, consequentemente, possibilitar o descobrimento\n",
    "    de suas fun√ß√µes, dentre outras aplica√ß√µes.\n",
    "\n",
    "FONTES: https://www.devmedia.com.br/naive-bayes-mineracao-de-dados-na-pratica-revista-sql-magazine-110/27490"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Sugest√£o e explica√ß√£o de melhorias reais no classificador:\n",
    "\n",
    "    Sugest√µes para melhoria na performance do nosso classificador:\n",
    "    - Aumentar a base de dados considerada para a constru√ß√£o do classificador (aumentando o valor do par√¢metro \"n\" no  \n",
    "    arquivo jupyter \"Projeto1_Obten√ß√£o_dos_tweets.ipynb\", que define a quantia m√≠nima de mensagens capturadas para a \n",
    "    base de treinamento, e classificando-os manualmente como relevantes ou irrelevantes). A partir dessa modifica√ß√£o, o \n",
    "    classificador ter√° mais dados nos quais se basear para fundamentar a classifica√ß√£o de futuros tweets, reduzindo a \n",
    "    taxa de erros nesse processo e melhorando a sua performance;\n",
    "    - Criar categorias intermedi√°rias de relev√¢ncia considerando a probabilidade (Para tal, deve-se criar novas vari√°veis \n",
    "    que classificam cada faixa de valor, dada em probabilidade, em uma categoria. Ademais, deve-se adicionar essa \n",
    "    classifica√ß√£o a uma coluna nova do tipo categ√≥rica no Dataframe). Considerando essa adapta√ß√£o, a probabilidade de \n",
    "    uma frase relevante, mesmo que em grau pequeno, ser classificada como irrelevante ser√° reduzida;\n",
    "    - Realizar o processo de treinamento e teste do classificador considerando as rela√ß√µes discursivas entre pares de \n",
    "    palavras (Como, por exemplo, \"concess√£o\", \"contraste\", etc.). Para isso, deve-se utilizar apenas as palavras das \n",
    "    classes substantivo e verbo uma vez que s√£o marcadores discursivos e, portanto, indicam tais rela√ß√µes. Dessa forma, \n",
    "    considerar atributos mais representativos que predizem as rela√ß√µes supracitadas de forma mais eficiente em conjunto\n",
    "    com o aumento da base de dados para treinamento pode aumentar ainda mais a efici√™ncia do classificador, fazendo com \n",
    "    que o seu desempenho aumente. \n",
    "    \n",
    "FONTES: https://sites.icmc.usp.br/taspardo/NILCTR0225-PardoNunes.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis  OK\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis OK\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o \n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento OK\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto OK\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa) OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  \n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) \n",
    "\n",
    "https://www.devmedia.com.br/naive-bayes-mineracao-de-dados-na-pratica-revista-sql-magazine-110/27490\n",
    "\n",
    "https://sites.icmc.usp.br/taspardo/NILCTR0225-PardoNunes.pdf\n",
    "\n",
    "https://stackoverflow.com/questions/49921720/how-to-split-emoji-from-each-other-python\n",
    "\n",
    "https://pypi.org/project/emoji/\n",
    "\n",
    "https://www.cos.ufrj.br/~ines/enia07_html/pdf/28095.pdf\n",
    "\n",
    "https://www.vooo.pro/insights/6-passos-faceis-para-aprender-o-algoritmo-naive-bayes-com-o-codigo-em-python/#:~:text=Dicas%20para%20melhorar%20o%20poder%20do%20modelo%20Naive%20Bayes,-Aqui%20v%C3%A3o%20algumas&text=Se%20o%20conjunto%20de%20dados,conjunto%20de%20dados%20de%20teste"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
