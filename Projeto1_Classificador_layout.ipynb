{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Andressa Silva de Oliveira\n",
    "\n",
    "Nome: Luana Mitsudo Coelho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aten√ß√£o:** Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Em `filename`, coloque o nome do seu arquivo de dados!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo xiaomi.xlsx, tudo certo para prosseguir com a prova!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filename = 'xiaomi.xlsx'\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com a prova!')\n",
    "else:\n",
    "    print(f'N√£o encontrei o arquivo {filename} aqui no diret√≥rio {os.getcwd()}, ser√° que voc√™ n√£o baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Valor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@miuirom miui 12 no rn8 xiaomi cade?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt @dani13_f: meu cell note 8 xiaomi j√° t√° com...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@notfakeholmes @brenomarquesof @arcanjobeni 3 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@juliaaacras o da xiaomi √© excelente, sem mais</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@rrlleal00 xiaomi mi 9 se. comprei na amazon e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Valor\n",
       "0               @miuirom miui 12 no rn8 xiaomi cade?      1\n",
       "1  rt @dani13_f: meu cell note 8 xiaomi j√° t√° com...      1\n",
       "2  @notfakeholmes @brenomarquesof @arcanjobeni 3 ...      1\n",
       "3     @juliaaacras o da xiaomi √© excelente, sem mais      1\n",
       "4  @rrlleal00 xiaomi mi 9 se. comprei na amazon e...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Valor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vcs acham msm que a c√¢mera d xiaomi √© melhor q...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pq as autorizadas do xiaomi s√≥ s√£o no toba do ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>üî• em stock! smart tvs xiaomi ao pre√ßo que quer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xiaomi poco x3 √© um verdadeiro sucesso de vend...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>quero refazer pq na √©poca eu usava o iphone 7 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Valor\n",
       "0  vcs acham msm que a c√¢mera d xiaomi √© melhor q...      1\n",
       "1  pq as autorizadas do xiaomi s√≥ s√£o no toba do ...      1\n",
       "2  üî• em stock! smart tvs xiaomi ao pre√ßo que quer...      0\n",
       "3  xiaomi poco x3 √© um verdadeiro sucesso de vend...      1\n",
       "4  quero refazer pq na √©poca eu usava o iphone 7 ...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "Escolhemos a marca Xiaomi e consideramos, para fins de an√°lise, que os tweets relevantes s√£o aqueles que elogiam de alguma forma, pedem melhorias ou criticam a marca e seus produtos. Na categoria n√£o relevantes foram classificados os tweets de propagandas de lojas e aqueles que mencionam o nome da marca mas n√£o se encaixam nas categorias j√° mencionadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/library/re.html#\n",
    "import re \n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Fun√ß√£o de limpeza muito simples que troca alguns sinais b√°sicos por espa√ßos\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[!-.:?;]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpando a base de dados para Treinamento\n",
    "treinamento_limpo = cleanup(\" \".join(train.Treinamento).lower())\n",
    "palavras_train = treinamento_limpo.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    @miuirom\n",
       "1                        miui\n",
       "2                          12\n",
       "3                          no\n",
       "4                         rn8\n",
       "                ...          \n",
       "7171                      g5s\n",
       "7172                   xiaomi\n",
       "7173                       mi\n",
       "7174                       a2\n",
       "7175    https//tco/gtqmqfuxso\n",
       "Length: 7176, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie_train = pd.Series(palavras_train)\n",
    "serie_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xiaomi    361\n",
       "o         190\n",
       "e         156\n",
       "de        156\n",
       "que       155\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_train_absoluta = serie_train.value_counts()\n",
    "tabela_train_absoluta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xiaomi    0.050307\n",
       "o         0.026477\n",
       "e         0.021739\n",
       "de        0.021739\n",
       "que       0.021600\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_train_relativa = serie_train.value_counts(True)\n",
    "tabela_train_relativa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa√ß√£o de twittes em relevantes e irrelevantes\n",
    "dados_R = train.loc[train.Valor == 1,:]\n",
    "dados_I = train.loc[train.Valor == 0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Organizando a base de dados separada em relevantes e irrelevantes\n",
    "dados_R_limpo = cleanup(\" \".join(dados_R.Treinamento).lower())\n",
    "dados_I_limpo = cleanup(\" \".join(dados_I.Treinamento).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa√ß√£o de palavras pertencentes a twittes relevantes e irrelevantes\n",
    "palavras_dados_R = dados_R_limpo.split()\n",
    "palavras_dados_I = dados_I_limpo.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41456582633053224\n",
      "0.5854341736694678\n"
     ]
    }
   ],
   "source": [
    "# Probabilidade de um twitte ser relevante ou irrelevante\n",
    "prob_relev = train.Valor.value_counts(True, sort=False)\n",
    "P_R = prob_relev[1]\n",
    "P_I = prob_relev[0]\n",
    "print(P_R)\n",
    "print(P_I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xiaomi    152\n",
       "o         103\n",
       "e          84\n",
       "a          84\n",
       "redmi      84\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_R = pd.Series(palavras_dados_R).value_counts()\n",
    "tabela_R.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xiaomi    209\n",
       "o          87\n",
       "que        76\n",
       "de         74\n",
       "e          72\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_I = pd.Series(palavras_dados_I).value_counts()\n",
    "tabela_I.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3572"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_R = tabela_R.sum()\n",
    "total_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3604"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_I = tabela_I.sum()\n",
    "total_I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase = \"quero refazer pq na √©poca eu usava o iphone 7 e agora eu tenho um xiaomi top e vai ficar bem mais legal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase = cleanup(frase.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quero',\n",
       " 'refazer',\n",
       " 'pq',\n",
       " 'na',\n",
       " '√©poca',\n",
       " 'eu',\n",
       " 'usava',\n",
       " 'o',\n",
       " 'iphone',\n",
       " '7',\n",
       " 'e',\n",
       " 'agora',\n",
       " 'eu',\n",
       " 'tenho',\n",
       " 'um',\n",
       " 'xiaomi',\n",
       " 'top',\n",
       " 'e',\n",
       " 'vai',\n",
       " 'ficar',\n",
       " 'bem',\n",
       " 'mais',\n",
       " 'legal']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frase = frase.split()\n",
    "frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vcs         0.000576\n",
       "acham       0.000115\n",
       "msm         0.000231\n",
       "que         0.009223\n",
       "a           0.009799\n",
       "c√¢mera      0.004496\n",
       "d           0.000115\n",
       "xiaomi      0.017639\n",
       "√©           0.009223\n",
       "melhor      0.001383\n",
       "que         0.009223\n",
       "iphone?     0.000115\n",
       "que         0.009223\n",
       "coragy!     0.000115\n",
       "n√£o         0.004611\n",
       "chega       0.000115\n",
       "nem         0.001038\n",
       "fodendo.    0.000115\n",
       "pode        0.000346\n",
       "ter         0.000576\n",
       "quantos     0.000115\n",
       "mp          0.000231\n",
       "quiser      0.000346\n",
       "fii...      0.000115\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Prob_frase_R = (tabela_R.reindex(frase,fill_value = 0)+1)/(total_R + len(frase)).prod()\n",
    "Prob_frase_R*P_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Valor</th>\n",
       "      <th>Limpos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vcs acham msm que a c√¢mera d xiaomi √© melhor q...</td>\n",
       "      <td>1</td>\n",
       "      <td>o l d   q u e   e u   v o u   e n a l t e c e ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pq as autorizadas do xiaomi s√≥ s√£o no toba do ...</td>\n",
       "      <td>1</td>\n",
       "      <td>o l d   q u e   e u   v o u   e n a l t e c e ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>üî• em stock! smart tvs xiaomi ao pre√ßo que quer...</td>\n",
       "      <td>0</td>\n",
       "      <td>o l d   q u e   e u   v o u   e n a l t e c e ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xiaomi poco x3 √© um verdadeiro sucesso de vend...</td>\n",
       "      <td>1</td>\n",
       "      <td>o l d   q u e   e u   v o u   e n a l t e c e ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>quero refazer pq na √©poca eu usava o iphone 7 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>o l d   q u e   e u   v o u   e n a l t e c e ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Valor  \\\n",
       "0  vcs acham msm que a c√¢mera d xiaomi √© melhor q...      1   \n",
       "1  pq as autorizadas do xiaomi s√≥ s√£o no toba do ...      1   \n",
       "2  üî• em stock! smart tvs xiaomi ao pre√ßo que quer...      0   \n",
       "3  xiaomi poco x3 √© um verdadeiro sucesso de vend...      1   \n",
       "4  quero refazer pq na √©poca eu usava o iphone 7 ...      1   \n",
       "\n",
       "                                              Limpos  \n",
       "0  o l d   q u e   e u   v o u   e n a l t e c e ...  \n",
       "1  o l d   q u e   e u   v o u   e n a l t e c e ...  \n",
       "2  o l d   q u e   e u   v o u   e n a l t e c e ...  \n",
       "3  o l d   q u e   e u   v o u   e n a l t e c e ...  \n",
       "4  o l d   q u e   e u   v o u   e n a l t e c e ...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limpando e criando uma coluna com cada tweet\n",
    "for a in test.Teste:\n",
    "    teste_limpo = cleanup(\" \".join(a).lower())\n",
    "    test.loc[:,'Limpos'] = teste_limpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test.Teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o l d   q u e   e u   v o u   e n a l t e c e r   a   m i n h a   c √¢ m e r a   d o   m e u   x i a o m i   r e d m i   n o t e   6   p r o   h t t p s  / / t  c o / f u f d e 4 g w w h\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Index(...) must be called with a collection of some kind, 'o l d   q u e   e u   v o u   e n a l t e c e r   a   m i n h a   c √¢ m e r a   d o   m e u   x i a o m i   r e d m i   n o t e   6   p r o   h t t p s  / / t  c o / f u f d e 4 g w w h' was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-dc4cc42a643c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLimpos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mProb_frase_R\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtabela_R\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfill_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_R\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mProb_frase_I\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtabela_I\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfill_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_I\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mProb_frase_R\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, index, **kwargs)\u001b[0m\n\u001b[0;32m   4028\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4029\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4030\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4032\u001b[0m     def drop(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   4542\u001b[0m         \u001b[1;31m# perform the reindex on the axes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4543\u001b[0m         return self._reindex_axes(\n\u001b[1;32m-> 4544\u001b[1;33m             \u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4545\u001b[0m         ).__finalize__(self)\n\u001b[0;32m   4546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   4557\u001b[0m             \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4558\u001b[0m             new_index, indexer = ax.reindex(\n\u001b[1;32m-> 4559\u001b[1;33m                 \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4560\u001b[0m             )\n\u001b[0;32m   4561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[0;32m   3128\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3129\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3130\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3132\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mensure_index\u001b[1;34m(index_like, copy)\u001b[0m\n\u001b[0;32m   5356\u001b[0m             \u001b[0mindex_like\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5358\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[0;32m    420\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scalar_data_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtupleize_cols\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Index(...) must be called with a collection of some kind, 'o l d   q u e   e u   v o u   e n a l t e c e r   a   m i n h a   c √¢ m e r a   d o   m e u   x i a o m i   r e d m i   n o t e   6   p r o   h t t p s  / / t  c o / f u f d e 4 g w w h' was passed"
     ]
    }
   ],
   "source": [
    "# Calculando a probabilidade de cada tweet ser relevante ou irrelevante\n",
    "for w in test.Limpos[0:1]:\n",
    "    print(w)\n",
    "    Prob_frase_R = (tabela_R.reindex(w,fill_value = 0)+1)/(total_R + len(frase)).prod()\n",
    "    Prob_frase_I = (tabela_I.reindex(w,fill_value = 0)+1)/(total_I + len(frase)).prod()\n",
    "    print(Prob_frase_R)\n",
    "    print(Prob_frase_I)\n",
    "    if (Prob_frase_R*P_R) > (Prob_frase_I*P_I):\n",
    "        test.loc[:,'Classificador'] = 1\n",
    "    else:\n",
    "        test.loc[:,'Classificador'] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela comparativa da classifica√ß√£o do modelo com a nossa\n",
    "tab = pd.crosstab(test['Classificador'],test['Valor'], normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Par√¢metros obtidos a partir da tabela\n",
    "Porc_R_classif_R = ###\n",
    "Porc_I_classif_R = \n",
    "Porc_I_classif_I = \n",
    "Porc_R_classif_I = \n",
    "\n",
    "print(f'Porcentagem de verdadeiros positivos = {Porc_R_classif_R}'\n",
    "print(f'Porcentagem de falsos positivos = {Porc_I_classif_R}'\n",
    "print(f'Porcentagem de verdadeiros negativos = {Porc_I_classif_I}'  \n",
    "print(f'Porcentagem de falsos negativos = {Porc_R_classif_I}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Conta quantas vezes a palavra apareceu na base de dados\n",
    "c = 0 \n",
    "for p in palavras_train:\n",
    "    if p == frase[i]:\n",
    "        c += 1\n",
    "# Calcula a probabilidade de uma palavra dada uma frase e a base de dados com todas as palavras\n",
    "c = 0 \n",
    "P = 1\n",
    "for i in len(frase):\n",
    "    for p in palavras_train:\n",
    "        if p == frase[i]:\n",
    "            c += 1\n",
    "    P *= ((c+1/(len(frase)+len(set(palavras_train)))))\n",
    "\n",
    " \n",
    "   \n",
    "    probFraseR = 1 *tabela_train_relativa[frase[i]]\n",
    "    probFraseI = 1 *tabela_train_relativa[frase[i]]\n",
    "    if frase[i] not in tabela_train_relativa:\n",
    "        frase[i] = 1\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Conferir emojis - espa√ßos? n√£o deleta mesmo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa um comparativo qualitativo sobre os percentuais obtidos para que possa discutir a\n",
    "performance do seu classificador.\n",
    "\n",
    "###Explique como s√£o tratadas as mensagens com dupla nega√ß√£o e sarcasmo.\n",
    "\n",
    "###Proponha um plano de expans√£o. Por que eles devem continuar financiando o seu\n",
    "projeto? - com as melhoris sugeridas abaixo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discorrer por que n√£o posso alimentar minha base de Treinamento\n",
    "automaticamente usando o pr√≥prio classificador, aplicado a novos tweets.\n",
    "\n",
    "     ###O classificador apresenta uma taxa "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propor diferentes cen√°rios de uso para o classificador Naive-Bayes. Pense em\n",
    "outros cen√°rios sem intersec√ß√£o com este projeto.\n",
    "\n",
    "    Dentre os cen√°rios em que pode-se usar o classificador Naive-Bayes, t√™m-se:\n",
    "    - Filtrar an√∫ncios em sites de forma personalizada para cada usu√°rio, classificando como relevantes aqueles que anunciam produtos, sites e servi√ßos que a pessoa usualmente busca;\n",
    "    - Filtrar e-mails, classificando-os como spam, principais, etc. de acordo com o conte√∫do (Por exemplo: se √© propaganda ou n√£o), com o remetente (Por exemplo: se √© um contato frequente ou uma conta comercial), dentre outras vari√†veis;\n",
    "    ###- Configurar um site com filtros para mostrar produtos a partir de carater√≠sticas selecionadas pelo usu√°rio (Por exemplo: Se um usu√°rio busca pela cor rosa, produtos com essa caractr√≠stica ser√£o dados como relevantes e aparecer√£o como resultado dessa busca)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sugerir e explicar melhorias reais no classificador com indica√ß√µes concretas de\n",
    "como implementar (n√£o √© preciso codificar, mas indicar como fazer. Indique\n",
    "material de pesquisa sobre o assunto).\n",
    "\n",
    "    Sugest√µes para melhoria na performance do nosso classificador:\n",
    "    - Aumentar a base de dados considerada para a constru√ß√£o do classificador (aumentando o valor do par√¢metro \"n\" no   arquivo jupyter \"Projeto1_Obten√ß√£o_dos_tweets.ipynb\", que define a quantia m√≠nima de mensagens capturadas para a base de treinamento e classificando-os manualmente como relevantes ou irrelevantes). A partir dessa modifica√ß√£o, o classificador ter√° mais dados nos quais se basear para fundamentar a classifica√ß√£o de futuros tweets, reduzindo a taxa de erros nesse processo;\n",
    "    - Criar categorias intermedi√°rias de relev√¢ncia considerando a probabilidade (Para tal, deve-se criar novas vari√°veis que classificam cada faixa de valor, dada em probabilidade, em uma categoria. Ademais, deve-se adicionar essa classifica√ß√£o a uma coluna nova do tipo categ√≥rica no Dataframe). Considerando essa adapta√ß√£o, a probabilidade de uma frase relevante, mesmo que em grau pequeno, ser classificada como irrelevante ser√° reduzida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis  OK\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis \n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "mt_relev = (P_R >= )|( == )\n",
    "relev = ( == )|( == )\n",
    "neutro = (dados['SENTIMENTO'] == 'Indiferente')\n",
    "irr = (dados['SENTIMENTO'] == 'Indiferente')\n",
    "mt_irr = (dados['SENTIMENTO'] == 'Indiferente')\n",
    "\n",
    "dados.loc[mt_relev,'SENTIMENTO'] = 'Muito Relevante'\n",
    "dados.loc[relev,'SENTIMENTO'] = 'Relevante'\n",
    "dados.loc[neutro,'SENTIMENTO'] = 'Neutro'\n",
    "dados.loc[irr,'SENTIMENTO'] = 'Irrelevante'\n",
    "dados.loc[mt_irr,'SENTIMENTO'] = 'Muito Irrelevante'\n",
    "\n",
    "dados['SENTIMENTO'] = dados['SENTIMENTO'].astype('category')\n",
    "dados['SENTIMENTO'] = pd.Categorical(dados.SENTIMENTO, \n",
    "                                     categories = ['Muito Relevante', 'Relevante', 'Neutro', 'Irrelevante', 'Muito Irrelevante'], \n",
    "                                     ordered=True)\n",
    "dados['SENTIMENTO'] = dados['SENTIMENTO'].cat.as_ordered()\n",
    "dados['SENTIMENTO']\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
