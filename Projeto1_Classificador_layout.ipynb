{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Andressa Silva de Oliveira\n",
    "\n",
    "Nome: Luana Mitsudo Coelho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aten√ß√£o:** Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Em `filename`, coloque o nome do seu arquivo de dados!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo xiaomi.xlsx, tudo certo para prosseguir com a prova!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filename = 'xiaomi.xlsx'\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com a prova!')\n",
    "else:\n",
    "    print(f'N√£o encontrei o arquivo {filename} aqui no diret√≥rio {os.getcwd()}, ser√° que voc√™ n√£o baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Valor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@miuirom miui 12 no rn8 xiaomi cade?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt @dani13_f: meu cell note 8 xiaomi j√° t√° com...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@notfakeholmes @brenomarquesof @arcanjobeni 3 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@juliaaacras o da xiaomi √© excelente, sem mais</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@rrlleal00 xiaomi mi 9 se. comprei na amazon e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Valor\n",
       "0               @miuirom miui 12 no rn8 xiaomi cade?      1\n",
       "1  rt @dani13_f: meu cell note 8 xiaomi j√° t√° com...      1\n",
       "2  @notfakeholmes @brenomarquesof @arcanjobeni 3 ...      1\n",
       "3     @juliaaacras o da xiaomi √© excelente, sem mais      1\n",
       "4  @rrlleal00 xiaomi mi 9 se. comprei na amazon e...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Valor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vcs acham msm que a c√¢mera d xiaomi √© melhor q...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pq as autorizadas do xiaomi s√≥ s√£o no toba do ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>üî• em stock! smart tvs xiaomi ao pre√ßo que quer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xiaomi poco x3 √© um verdadeiro sucesso de vend...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>quero refazer pq na √©poca eu usava o iphone 7 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Valor\n",
       "0  vcs acham msm que a c√¢mera d xiaomi √© melhor q...      1\n",
       "1  pq as autorizadas do xiaomi s√≥ s√£o no toba do ...      1\n",
       "2  üî• em stock! smart tvs xiaomi ao pre√ßo que quer...      0\n",
       "3  xiaomi poco x3 √© um verdadeiro sucesso de vend...      1\n",
       "4  quero refazer pq na √©poca eu usava o iphone 7 ...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "Escolhemos a marca Xiaomi e consideramos, para fins de an√°lise, que os tweets relevantes s√£o aqueles que elogiam de alguma forma, pedem melhorias ou criticam a marca e seus produtos. Na categoria n√£o relevantes foram classificados os tweets de propagandas de lojas e aqueles que mencionam o nome da marca mas n√£o se encaixam nas categorias j√° mencionadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/library/re.html#\n",
    "import re \n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Fun√ß√£o de limpeza muito simples que troca alguns sinais b√°sicos por espa√ßos\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[!-.:?;]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpando a base de dados para Treinamento\n",
    "treinamento_limpo = cleanup(\" \".join(train.Treinamento).lower())\n",
    "palavras_train = treinamento_limpo.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    @miuirom\n",
       "1                        miui\n",
       "2                          12\n",
       "3                          no\n",
       "4                         rn8\n",
       "                ...          \n",
       "7171                      g5s\n",
       "7172                   xiaomi\n",
       "7173                       mi\n",
       "7174                       a2\n",
       "7175    https//tco/gtqmqfuxso\n",
       "Length: 7176, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie_train = pd.Series(palavras_train)\n",
    "serie_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xiaomi    361\n",
       "o         190\n",
       "e         156\n",
       "de        156\n",
       "que       155\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_train_absoluta = serie_train.value_counts()\n",
    "tabela_train_absoluta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xiaomi    0.050307\n",
       "o         0.026477\n",
       "e         0.021739\n",
       "de        0.021739\n",
       "que       0.021600\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_train_relativa = serie_train.value_counts(True)\n",
    "tabela_train_relativa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa√ß√£o de twittes em relevantes e irrelevantes\n",
    "dados_R = train.loc[train.Valor == 1,:]\n",
    "dados_I = train.loc[train.Valor == 0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Organizando a base de dados separada em relevantes e irrelevantes\n",
    "dados_R_limpo = cleanup(\" \".join(dados_R.Treinamento).lower())\n",
    "dados_I_limpo = cleanup(\" \".join(dados_I.Treinamento).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa√ß√£o de palavras pertencentes a twittes relevantes e irrelevantes\n",
    "palavras_dados_R = dados_R_limpo.split()\n",
    "palavras_dados_I = dados_I_limpo.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41456582633053224\n",
      "0.5854341736694678\n"
     ]
    }
   ],
   "source": [
    "# Probabilidade de um twitte ser relevante ou irrelevante\n",
    "prob_relev = train.Valor.value_counts(True, sort=False)\n",
    "P_R = prob_relev[1]\n",
    "P_I = prob_relev[0]\n",
    "print(P_R)\n",
    "print(P_I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xiaomi    152\n",
       "o         103\n",
       "a          84\n",
       "redmi      84\n",
       "e          84\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_R = pd.Series(palavras_dados_R).value_counts()\n",
    "tabela_R.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xiaomi    209\n",
       "o          87\n",
       "que        76\n",
       "de         74\n",
       "e          72\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_I = pd.Series(palavras_dados_I).value_counts()\n",
    "tabela_I.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3572"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_R = tabela_R.sum()\n",
    "total_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3604"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_I = tabela_I.sum()\n",
    "total_I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase = \"quero refazer pq na √©poca eu usava o iphone 7 e agora eu tenho um xiaomi top e vai ficar bem mais legal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase = cleanup(frase.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quero',\n",
       " 'refazer',\n",
       " 'pq',\n",
       " 'na',\n",
       " '√©poca',\n",
       " 'eu',\n",
       " 'usava',\n",
       " 'o',\n",
       " 'iphone',\n",
       " '7',\n",
       " 'e',\n",
       " 'agora',\n",
       " 'eu',\n",
       " 'tenho',\n",
       " 'um',\n",
       " 'xiaomi',\n",
       " 'top',\n",
       " 'e',\n",
       " 'vai',\n",
       " 'ficar',\n",
       " 'bem',\n",
       " 'mais',\n",
       " 'legal']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frase = frase.split()\n",
    "frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quero      0.000461\n",
       "refazer    0.000115\n",
       "pq         0.001153\n",
       "na         0.001960\n",
       "√©poca      0.000231\n",
       "eu         0.005535\n",
       "usava      0.000115\n",
       "o          0.011993\n",
       "iphone     0.001384\n",
       "7          0.001268\n",
       "e          0.009802\n",
       "agora      0.000807\n",
       "eu         0.005535\n",
       "tenho      0.001268\n",
       "um         0.006458\n",
       "xiaomi     0.017644\n",
       "top        0.000346\n",
       "e          0.009802\n",
       "vai        0.000461\n",
       "ficar      0.000346\n",
       "bem        0.000692\n",
       "mais       0.002537\n",
       "legal      0.000115\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Prob_frase_R = (tabela_R.reindex(frase,fill_value = 0)+1)/(total_R + len(frase)).prod()\n",
    "Prob_frase_R*P_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpando e criando uma coluna com cada tweet\n",
    "cont = 0\n",
    "for a in test.Teste:\n",
    "    teste_limpo = cleanup(a).lower()\n",
    "    test.loc[cont,'Limpos'] = teste_limpo\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Valor</th>\n",
       "      <th>Limpos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vcs acham msm que a c√¢mera d xiaomi √© melhor q...</td>\n",
       "      <td>1</td>\n",
       "      <td>vcs acham msm que a c√¢mera d xiaomi √© melhor q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pq as autorizadas do xiaomi s√≥ s√£o no toba do ...</td>\n",
       "      <td>1</td>\n",
       "      <td>pq as autorizadas do xiaomi s√≥ s√£o no toba do ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>üî• em stock! smart tvs xiaomi ao pre√ßo que quer...</td>\n",
       "      <td>0</td>\n",
       "      <td>üî• em stock smart tvs xiaomi ao pre√ßo que queri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xiaomi poco x3 √© um verdadeiro sucesso de vend...</td>\n",
       "      <td>1</td>\n",
       "      <td>xiaomi poco x3 √© um verdadeiro sucesso de vend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>quero refazer pq na √©poca eu usava o iphone 7 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>quero refazer pq na √©poca eu usava o iphone 7 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Valor  \\\n",
       "0  vcs acham msm que a c√¢mera d xiaomi √© melhor q...      1   \n",
       "1  pq as autorizadas do xiaomi s√≥ s√£o no toba do ...      1   \n",
       "2  üî• em stock! smart tvs xiaomi ao pre√ßo que quer...      0   \n",
       "3  xiaomi poco x3 √© um verdadeiro sucesso de vend...      1   \n",
       "4  quero refazer pq na √©poca eu usava o iphone 7 ...      1   \n",
       "\n",
       "                                              Limpos  \n",
       "0  vcs acham msm que a c√¢mera d xiaomi √© melhor q...  \n",
       "1  pq as autorizadas do xiaomi s√≥ s√£o no toba do ...  \n",
       "2  üî• em stock smart tvs xiaomi ao pre√ßo que queri...  \n",
       "3  xiaomi poco x3 √© um verdadeiro sucesso de vend...  \n",
       "4  quero refazer pq na √©poca eu usava o iphone 7 ...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test.Teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['üî•', 'em', 'stock', 'smart', 'tvs', 'xiaomi', 'ao', 'pre√ßo', 'que', 'querias', 'üëâ', 'https//tco/dadrkzme3p', 'xiaomi', 'tv', 'smarttv', 'televisor', 'https//tco/wlvxfqphrj']\n"
     ]
    }
   ],
   "source": [
    "# Calculando a probabilidade de cada tweet ser relevante ou irrelevante\n",
    "lista_palavras_separadas = []\n",
    "for frase in test.Limpos:\n",
    "    lista_palavras_separadas.append(frase.split())\n",
    "print(lista_palavras_separadas[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-45e3ad9eb755>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mProb_frase_R\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtabela_R\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfill_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_R\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mProb_frase_I\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtabela_I\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfill_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_I\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mProb_frase_R\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mP_R\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mProb_frase_I\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mP_I\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcont2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Classificador'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1477\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1478\u001b[0m         raise ValueError(\n\u001b[1;32m-> 1479\u001b[1;33m             \u001b[1;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1480\u001b[0m             \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1481\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "cont2 = 0\n",
    "for p in lista_palavras_separadas:\n",
    "    Prob_frase_R = (tabela_R.reindex(p,fill_value = 0)+1)/(total_R + len(p)).prod()\n",
    "    Prob_frase_I = (tabela_I.reindex(p,fill_value = 0)+1)/(total_I + len(p)).prod()\n",
    "    if (Prob_frase_R*P_R) > (Prob_frase_I*P_I):\n",
    "        test.loc[cont2,'Classificador'] = 1\n",
    "    else:\n",
    "        test.loc[cont2,'Classificador'] = 0\n",
    "    cont2 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "i = 0\n",
    "a = 0\n",
    "while i <= len(lista_palavras_separadas) and a <= len(lista_palavras_separadas[i]):\n",
    "    Prob_frase_R = (tabela_R.reindex(lista_palavras_separadas[i][a],fill_value = 0)+1)/(total_R + len(lista_palavras_separadas[i])).prod()\n",
    "    Prob_frase_I = (tabela_I.reindex(lista_palavras_separadas[i][a],fill_value = 0)+1)/(total_I + len(lista_palavras_separadas[i])).prod()\n",
    "    if (Prob_frase_R*P_R) > (Prob_frase_I*P_I):\n",
    "        test.loc[i,'Classificador'] = 1\n",
    "    else:\n",
    "        test.loc[i,'Classificador'] = 0\n",
    "    i += 1\n",
    "    a += 1\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Classificador'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Classificador'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-d9038f7c02fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Tabela comparativa da classifica√ß√£o do modelo com a nossa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrosstab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Classificador'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Valor'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Classificador'"
     ]
    }
   ],
   "source": [
    "# Tabela comparativa da classifica√ß√£o do modelo com a nossa\n",
    "tab = pd.crosstab(test['Classificador'],test['Valor'], normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-bc62176fad8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tab' is not defined"
     ]
    }
   ],
   "source": [
    "tab[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-27-2649fea1352a>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-27-2649fea1352a>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    Porc_R_classif_R = ###\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Par√¢metros obtidos a partir da tabela\n",
    "Porc_R_classif_R = ###\n",
    "Porc_I_classif_R = \n",
    "Porc_I_classif_I = \n",
    "Porc_R_classif_I = \n",
    "\n",
    "print(f'Porcentagem de verdadeiros positivos = {Porc_R_classif_R}'\n",
    "print(f'Porcentagem de falsos positivos = {Porc_I_classif_R}'\n",
    "print(f'Porcentagem de verdadeiros negativos = {Porc_I_classif_I}'  \n",
    "print(f'Porcentagem de falsos negativos = {Porc_R_classif_I}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Conta quantas vezes a palavra apareceu na base de dados\\nc = 0 \\nfor p in palavras_train:\\n    if p == frase[i]:\\n        c += 1\\n# Calcula a probabilidade de uma palavra dada uma frase e a base de dados com todas as palavras\\nc = 0 \\nP = 1\\nfor i in len(frase):\\n    for p in palavras_train:\\n        if p == frase[i]:\\n            c += 1\\n    P *= ((c+1/(len(frase)+len(set(palavras_train)))))\\n\\n \\n   \\n    probFraseR = 1 *tabela_train_relativa[frase[i]]\\n    probFraseI = 1 *tabela_train_relativa[frase[i]]\\n    if frase[i] not in tabela_train_relativa:\\n        frase[i] = 1\\n        '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Conta quantas vezes a palavra apareceu na base de dados\n",
    "c = 0 \n",
    "for p in palavras_train:\n",
    "    if p == frase[i]:\n",
    "        c += 1\n",
    "# Calcula a probabilidade de uma palavra dada uma frase e a base de dados com todas as palavras\n",
    "c = 0 \n",
    "P = 1\n",
    "for i in len(frase):\n",
    "    for p in palavras_train:\n",
    "        if p == frase[i]:\n",
    "            c += 1\n",
    "    P *= ((c+1/(len(frase)+len(set(palavras_train)))))\n",
    "\n",
    " \n",
    "   \n",
    "    probFraseR = 1 *tabela_train_relativa[frase[i]]\n",
    "    probFraseI = 1 *tabela_train_relativa[frase[i]]\n",
    "    if frase[i] not in tabela_train_relativa:\n",
    "        frase[i] = 1\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Conferir emojis - espa√ßos? n√£o deleta mesmo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa um comparativo qualitativo sobre os percentuais obtidos para que possa discutir a\n",
    "performance do seu classificador.\n",
    "\n",
    "###Explique como s√£o tratadas as mensagens com dupla nega√ß√£o e sarcasmo.\n",
    "\n",
    "###Proponha um plano de expans√£o. Por que eles devem continuar financiando o seu\n",
    "projeto? - com as melhoris sugeridas abaixo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discorrer por que n√£o posso alimentar minha base de Treinamento\n",
    "automaticamente usando o pr√≥prio classificador, aplicado a novos tweets.\n",
    "\n",
    "     ### A base de treinamento n√£o pode ser alimentada automaticamente com o uso do pr√≥prio classificador uma vez que este aprende com os tweets j√° classificados, manualmente, como relevantes ou irrelevantes. Dessa forma, se o classificador criasse novos tweets para sua base de treinamento, ele n√£o estaria aperfei√ßoando a sua an√°lise, mas sim aplicando aquilo que j√° aprendeu anteriomente, ent√£o n√£o haveria melhora na precis√£o das previs√µes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propor diferentes cen√°rios de uso para o classificador Naive-Bayes. Pense em\n",
    "outros cen√°rios sem intersec√ß√£o com este projeto.\n",
    "\n",
    "    Dentre os cen√°rios em que pode-se usar o classificador Naive-Bayes, t√™m-se:\n",
    "    - Filtrar an√∫ncios em sites de forma personalizada para cada usu√°rio, classificando como relevantes aqueles que anunciam produtos, sites e servi√ßos que a pessoa usualmente busca;\n",
    "    - Filtrar e-mails, classificando-os como spam, principais, etc. de acordo com o conte√∫do (Por exemplo: se √© propaganda ou n√£o), com o remetente (Por exemplo: se √© um contato frequente ou uma conta comercial), dentre outras vari√†veis;\n",
    "    ###- Configurar um site com filtros para mostrar produtos a partir de carater√≠sticas selecionadas pelo usu√°rio (Por exemplo: Se um usu√°rio busca pela cor rosa, produtos com essa caractr√≠stica ser√£o dados como relevantes e aparecer√£o como resultado dessa busca)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sugerir e explicar melhorias reais no classificador com indica√ß√µes concretas de\n",
    "como implementar (n√£o √© preciso codificar, mas indicar como fazer. Indique\n",
    "material de pesquisa sobre o assunto).\n",
    "\n",
    "    Sugest√µes para melhoria na performance do nosso classificador:\n",
    "    - Aumentar a base de dados considerada para a constru√ß√£o do classificador (aumentando o valor do par√¢metro \"n\" no   arquivo jupyter \"Projeto1_Obten√ß√£o_dos_tweets.ipynb\", que define a quantia m√≠nima de mensagens capturadas para a base de treinamento e classificando-os manualmente como relevantes ou irrelevantes). A partir dessa modifica√ß√£o, o classificador ter√° mais dados nos quais se basear para fundamentar a classifica√ß√£o de futuros tweets, reduzindo a taxa de erros nesse processo;\n",
    "    - Criar categorias intermedi√°rias de relev√¢ncia considerando a probabilidade (Para tal, deve-se criar novas vari√°veis que classificam cada faixa de valor, dada em probabilidade, em uma categoria. Ademais, deve-se adicionar essa classifica√ß√£o a uma coluna nova do tipo categ√≥rica no Dataframe). Considerando essa adapta√ß√£o, a probabilidade de uma frase relevante, mesmo que em grau pequeno, ser classificada como irrelevante ser√° reduzida.\n",
    "    - ########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis  OK\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis #######\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o #########\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento OK\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto OK\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa) OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "mt_relev = (P_R >= )|( == )\n",
    "relev = ( == )|( == )\n",
    "neutro = (dados['SENTIMENTO'] == 'Indiferente')\n",
    "irr = (dados['SENTIMENTO'] == 'Indiferente')\n",
    "mt_irr = (dados['SENTIMENTO'] == 'Indiferente')\n",
    "\n",
    "dados.loc[mt_relev,'SENTIMENTO'] = 'Muito Relevante'\n",
    "dados.loc[relev,'SENTIMENTO'] = 'Relevante'\n",
    "dados.loc[neutro,'SENTIMENTO'] = 'Neutro'\n",
    "dados.loc[irr,'SENTIMENTO'] = 'Irrelevante'\n",
    "dados.loc[mt_irr,'SENTIMENTO'] = 'Muito Irrelevante'\n",
    "\n",
    "dados['SENTIMENTO'] = dados['SENTIMENTO'].astype('category')\n",
    "dados['SENTIMENTO'] = pd.Categorical(dados.SENTIMENTO, \n",
    "                                     categories = ['Muito Relevante', 'Relevante', 'Neutro', 'Irrelevante', 'Muito Irrelevante'], \n",
    "                                     ordered=True)\n",
    "dados['SENTIMENTO'] = dados['SENTIMENTO'].cat.as_ordered()\n",
    "dados['SENTIMENTO']\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
